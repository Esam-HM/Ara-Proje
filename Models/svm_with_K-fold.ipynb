{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeH6GzR-9Zp7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix,ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdOOkB7pgTb6"
      },
      "source": [
        "## Gerekli fonksiyonlar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxTstB--9Xdz"
      },
      "outputs": [],
      "source": [
        "def pad_image(image_path):\n",
        "  image = Image.open(image_path).convert('RGB')\n",
        "  new_img = Image.new('RGB',(350,350),color=0)\n",
        "  image = T.Resize(224,max_size=320)(image)\n",
        "  x = (new_img.width - image.width) // 2\n",
        "  y = (new_img.height - image.height) // 2\n",
        "  new_img.paste(image,(x,y))\n",
        "  return new_img, new_img.size\n",
        "\n",
        "def sort_image_list(lst):\n",
        "  new_lst = []\n",
        "  extensions = {}\n",
        "  for i in range(0,len(lst)):\n",
        "    id = Path(lst[i]).stem\n",
        "    extensions[id] = lst[i][-4:]\n",
        "    new_lst.append(int(id))\n",
        "\n",
        "  new_lst = sorted(new_lst)\n",
        "\n",
        "  for i in range(0,len(lst)):\n",
        "    id = str(new_lst[i])\n",
        "    new_lst[i]= id + extensions[id]\n",
        "  return new_lst\n",
        "\n",
        "def display_images_labels(imgs_lst,image_label_dictionary):\n",
        "  return pd.DataFrame({\n",
        "      \"Image\" : [img for img in imgs_lst],\n",
        "      \"Label\" : [image_label_dictionary[img] for img in imgs_lst]\n",
        "  })\n",
        "\n",
        "def create_images_list(dir,sort=False,fullPath=False):\n",
        "  lst = os.listdir(dir)\n",
        "\n",
        "  if sort:\n",
        "    lst = sort_image_list(lst)\n",
        "\n",
        "  if fullPath:\n",
        "    for i,img in enumerate(lst):\n",
        "      path = os.path.join(dir,img)\n",
        "      lst[i] = path\n",
        "\n",
        "  return lst\n",
        "\n",
        "def merge_image_directories(dir1,dir2,sort=False,fullPath=False):\n",
        "  list1 = create_images_list(dir1,sort,fullPath)\n",
        "  list2 = create_images_list(dir2,sort,fullPath)\n",
        "  total = list1 + list2\n",
        "  return total\n",
        "\n",
        "def get_selected_indexes(indexes:list,elements:list):\n",
        "  arr = []\n",
        "  for idx in indexes:\n",
        "    arr.append(elements[idx])\n",
        "  return arr\n",
        "\n",
        "def get_labels(images,image_lbl_dict):\n",
        "  arr = []\n",
        "  for img in images:\n",
        "    arr.append(image_lbl_dict[img])\n",
        "  return arr\n",
        "\n",
        "## Image list must be sorted before call this function.\n",
        "## For sorting call sort_image_list function before.\n",
        "def create_img_label_dict(imgs_lst,labels_lst,column_num:int):\n",
        "  _dict = {}\n",
        "  for i,img in enumerate(imgs_lst):\n",
        "    _dict[img] = labels_lst.iloc[i,column_num]\n",
        "  return _dict\n",
        "\n",
        "def create_cm(actual_labels,predicted,classes):\n",
        "  cm = confusion_matrix(actual_labels, predicted)\n",
        "  cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "  cm_display.plot()\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.show()\n",
        "\n",
        "def search(arr,idx,element):\n",
        "  if element ==-1:\n",
        "    j=idx+1\n",
        "    element = arr[idx]\n",
        "  else:\n",
        "    j=0\n",
        "  while j<len(arr):\n",
        "    if element == arr[j]:\n",
        "      return element\n",
        "    else:\n",
        "      j+=1\n",
        "  return -1\n",
        "\n",
        "def getNotFoundElements(arr1,arr2):\n",
        "  not_found= []\n",
        "  for elm in arr1:\n",
        "    xx = search(arr2,-1,elm)\n",
        "    if xx ==-1:\n",
        "      not_found.append(elm)\n",
        "  return not_found\n",
        "\n",
        "def load_image(image,transform):\n",
        "  new_img, _ = pad_image(image)\n",
        "  new_img = transform(new_img)[:3].unsqueeze(0)\n",
        "  return new_img\n",
        "\n",
        "def compute_embeddings(image_paths,device,transform,transformer):\n",
        "  all_embeddings = {}\n",
        "  with torch.no_grad():\n",
        "    for _, img in enumerate(tqdm(image_paths,desc=\"Processing files\")):\n",
        "      embeddings = transformer(load_image(img,transform).to(device))\n",
        "      all_embeddings[img] = np.array(embeddings[0].cpu().numpy()).reshape(1, -1).tolist()\n",
        "\n",
        "  #with open(\"all_embeddings.json\", \"w\") as f:\n",
        "      #f.write(json.dumps(all_embeddings))\n",
        "  \n",
        "  lst = list(all_embeddings.values())\n",
        "  return lst\n",
        "\n",
        "def calculate_metrics(labels,predictions):\n",
        "  f1 = f1_score(labels,predictions)\n",
        "  precision = precision_score(labels,predictions)\n",
        "  recall = recall_score(labels,predictions)\n",
        "  accuracy = accuracy_score(labels,predictions)\n",
        "  return accuracy, precision, recall, f1\n",
        "\n",
        "def test_model(test_images,img_lbl_dict,classes,model,transformer,transform):\n",
        "  with torch.no_grad():\n",
        "    embeddings = np.array(compute_embeddings(test_images,device,transform,transformer)).reshape(-1,384)\n",
        "    predictions = model.predict(embeddings)\n",
        "    labels = get_labels(test_images,img_lbl_dict)\n",
        "    res = calculate_metrics(labels,predictions)\n",
        "    print(f\"Accuracy: {res[0]}, Precision: {res[1]}, Recall: {res[2]}, F1 score: {res[3]}\")\n",
        "    create_cm(labels,predictions,classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZLWMYQh9UfK"
      },
      "outputs": [],
      "source": [
        "furkan_images_dir = \"./dataset/Furkan_Pan/images\"\n",
        "gamze_images_dir = \"./dataset/Gamze_Pan/images\"\n",
        "furkan_excel_path = \"./dataset/Furkan_Excel.xlsx\"\n",
        "gamze_excel_path = \"./dataset/Gamze_Excel.xlsx\"\n",
        "total_excel_path = \"./dataset/Total_Excel.xlsx\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "transform = T.Compose([T.ToTensor(),T.Normalize([0.5], [0.5])])\n",
        "classes = [\"Hatasız\",\"Hatalı\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "aMyrqo0j9SY6",
        "outputId": "a7062c56-3a5c-46bc-d6f1-bf077d95dec0"
      },
      "outputs": [],
      "source": [
        "labels_file = pd.read_excel(total_excel_path,header=None,keep_default_na=False)\n",
        "total_images_paths = merge_image_directories(furkan_images_dir,gamze_images_dir,sort=True,fullPath=True)\n",
        "img_lbl_dict = create_img_label_dict(total_images_paths,labels_file,column_num=1)\n",
        "pd.Series({\n",
        "    \"labels file length =\" : len(labels_file),\n",
        "    \"images list length =\" : len(total_images_paths),\n",
        "    \"dictionary  length =\" : len(img_lbl_dict)\n",
        "}).to_frame().style.hide(axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm5jm1i72dMS",
        "outputId": "89356ecb-f553-46bc-869d-7a62029aa1a2"
      },
      "outputs": [],
      "source": [
        "images_paths = random.sample(total_images_paths,1400)         ## Get 1400 sample randomly for training.\n",
        "print(f\"For train: {len(images_paths)}, Total: {len(total_images_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTLExezU9YLr",
        "outputId": "cee78a7f-a020-42cf-b6f4-8a7984d7cbaf"
      },
      "outputs": [],
      "source": [
        "#print(f\"Repeated Elements: {findRepeatedElements(images_paths)}\")\n",
        "test_images = getNotFoundElements(total_images_paths,images_paths)\n",
        "print(f\"Test images: {len(test_images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "bP9ffzLPdsvu",
        "outputId": "5f63f926-1e8f-498d-a5ab-21b27aa913c3"
      },
      "outputs": [],
      "source": [
        "display_images_labels(images_paths,img_lbl_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI1J9ynAjoMT"
      },
      "source": [
        "## Hangi resize işlemi kullanayım diye bu iki scripti çalıştırıyorum.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "cyE1SdGYFU_j",
        "outputId": "80041911-549a-4643-dc5e-7078c950fd60"
      },
      "outputs": [],
      "source": [
        "path = random.choice(total_images_paths)\n",
        "sample = Image.open(path).convert('RGB')\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "4fDFhvRXFpvL",
        "outputId": "db2f31b1-255e-4e56-f866-069197a2856e"
      },
      "outputs": [],
      "source": [
        "transformed = T.Resize((350,350))(sample)\n",
        "transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "gpm18PQ8dtaV",
        "outputId": "267b0334-a917-4f48-b83e-a205ee08c59a"
      },
      "outputs": [],
      "source": [
        "img, info = pad_image(path,224)\n",
        "print(info)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWsDEaEndwRe",
        "outputId": "0bd604fe-00ef-475e-80e0-42607a5f10a4"
      },
      "outputs": [],
      "source": [
        "dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "dinov2_vits14 = dinov2_vits14.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBhlAVEed209"
      },
      "outputs": [],
      "source": [
        "clf = svm.SVC(probability=True,gamma='scale')               ## Initialize classifier\n",
        "batch_size = 20                                             ## batch size\n",
        "num_epochs = 1                                              ## Number of epochs\n",
        "K = 5                                                       ## Number of folds\n",
        "kf = KFold(n_splits=K)                                      ## Define K-Fold method for cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNKatcvEsqXi",
        "outputId": "0bf8ba4d-73b4-48d3-ed1f-a16bc7998d7e"
      },
      "outputs": [],
      "source": [
        "## Train loop\n",
        "metrics = []\n",
        "model = None\n",
        "for i, (train_index, test_index) in enumerate(kf.split(images_paths)):\n",
        "  print(f\"Fold {i+1}/{K}\")\n",
        "  ## Get select images for train/test folds.\n",
        "  x_train = get_selected_indexes(train_index,images_paths)\n",
        "  x_test  = get_selected_indexes(test_index,images_paths)\n",
        "\n",
        "  ## Get corresponding labels.\n",
        "  y_train = get_labels(x_train,img_lbl_dict)\n",
        "  y_test = get_labels(x_test,img_lbl_dict)\n",
        "\n",
        "  ## Compute embeddings for train/test images.\n",
        "  train_embeddings = np.array(compute_embeddings(x_train,device,transform,dinov2_vits14)).reshape(-1,384)\n",
        "  test_embeddings = np.array(compute_embeddings(x_test,device,transform,dinov2_vits14)).reshape(-1,384)\n",
        "\n",
        "  model = clf.fit(x_train,y_train)\n",
        "  predictions = model.predict(x_test)\n",
        "\n",
        "  res = calculate_metrics(y_test,predictions)\n",
        "  create_cm(y_test,predictions,classes)          ## Draw confusion matrix\n",
        "  metrics.append(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPRm4KQ5kuaj"
      },
      "outputs": [],
      "source": [
        "## Save the model\n",
        "project_dir = Path(\"/content/drive/MyDrive/Models/\")\n",
        "project_dir.mkdir(parents=True, exist_ok=True)\n",
        "with open('/content/drive/MyDrive/Models/dinv2_vit14_model.pth', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njb3g4jBnoMM"
      },
      "source": [
        "## Training sonucunda modelin performansı gösterme\n",
        "## Aşağıdaki iki plot, her fold'un son accuracy ve loss değerleri gösterir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_acc, avg_precision, avg_recall, avg_f1= 0, 0, 0, 0\n",
        "acc = []\n",
        "length = len(metrics)\n",
        "for i in range(length):\n",
        "    avg_acc += metrics[i][0]\n",
        "    acc.append(metrics[i][0])\n",
        "    avg_precision += metrics[i][1]\n",
        "    avg_recall += metrics[i][2]\n",
        "    avg_f1 += metrics[i][3]\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"Average Accuracy\" : 100*avg_acc/length\n",
        "    \"Average Precision\": 100*avg_precision/length\n",
        "    \"Average Recall\" : 100*avg_recall/length\n",
        "    \"Average F1 Score\" : 100*avg_f1/length\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "MmjqUCHw6slK",
        "outputId": "fee723ea-9022-43cc-bfdb-6b72dbc64c8c"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(1,K+1),acc,color=\"blue\",linewidth = 2,marker='o', markerfacecolor='red', markersize=12)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"Fold\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQSx4mxykZva"
      },
      "source": [
        "## Sadece 97 resim üzerinde test yapar.\n",
        "Bu resimler training aşamasına dahil edilmedi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "nCbwpp9mLko6",
        "outputId": "0deeb0e1-f1e0-4cfa-8c42-31d9a069c1db"
      },
      "outputs": [],
      "source": [
        "test_model(test_images,img_lbl_dict,classes,model,dinov2_vits14,transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFHXm1fTkeoy"
      },
      "source": [
        "## Bütün resimler için test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model(total_images_paths,img_lbl_dict,classes,model,dinov2_vits14,transform)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
